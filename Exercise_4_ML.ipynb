{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPQ-nUhQ3EH6"
      },
      "source": [
        "# Packs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qd2V-7N0hRO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.model_selection import StratifiedShuffleSplit , StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WxWO08u3C6a"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  root_dir = '/content/drive/'\n",
        "  drive_prefix = 'MyDrive/'\n",
        "  drive.mount(root_dir)\n",
        "else:\n",
        "  root_dir = '/home/ehudmal/ML_Course_works/assignment_4'\n",
        "  drive_prefix = ''\n",
        "\n",
        "project_dir = os.path.join(root_dir, f'{drive_prefix}Flowers_datasets_ML_EX_4')\n",
        "pictures_dir = os.path.join(project_dir, '102_flowers_jpg')\n",
        "labels_path = os.path.join(project_dir, 'imagelabels.mat')\n",
        "splits = os.path.join(project_dir, 'setid.mat')\n",
        "split = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJrT_iuTcZDX"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    non_trainable_params = total_params - trainable_params\n",
        "    res = f\"\"\"\n",
        "    Total model parameters: {total_params}\n",
        "    Total trainable parameters: {trainable_params}\n",
        "    Total non-trainable parameters: {non_trainable_params}\n",
        "    \"\"\"\n",
        "    print(res)\n",
        "    return total_params, trainable_params, non_trainable_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iHOGW8O-Okx"
      },
      "source": [
        "# Data preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5_qMsjI-Q1A",
        "outputId": "d4cdfdb3-474d-4dcd-ca13-d1eb1f0d6241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(102, 8189, np.int64(0))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_vector = sio.loadmat(labels_path)\n",
        "len(np.unique(labels_vector['labels'][0])), np.count_nonzero(labels_vector['labels'][0]), (labels_vector['labels'][0] == 0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "F4AyQo-9MUsN",
        "outputId": "56d55084-6d70-483f-a18f-7645d3d5ac8f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes, n_for_class = np.unique(labels_vector['labels'][0], return_counts=True)\n",
        "plt.bar(classes, n_for_class)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmw_sX-0EC--"
      },
      "source": [
        "Checking files length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xZ_33TKF85J",
        "outputId": "248eff53-cd70-405c-c3ad-c42669d83893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File names have different lengths.\n",
            "Unique lengths found: {9, 7}\n"
          ]
        }
      ],
      "source": [
        "files_in_dir = os.listdir(pictures_dir)\n",
        "file_name_lengths = [len(file_name) for file_name in files_in_dir]\n",
        "if len(set(file_name_lengths)) == 1:\n",
        "    print(f\"All file names have the same length: {file_name_lengths[0]}\")\n",
        "else:\n",
        "    print(\"File names have different lengths.\")\n",
        "    print(f\"Unique lengths found: {set(file_name_lengths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILRton9qF95j"
      },
      "source": [
        "Validating files names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwf3eIQCFtec",
        "outputId": "6f410a16-d30a-4433-c89b-677df329e90c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all([f'image_{str(i+1).zfill(5)}.jpg' in files_in_dir for i in range(len(labels_vector['labels'][0]))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6u5_ychGYbJ"
      },
      "source": [
        "Mapping picture to label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZLqBbe4AShL",
        "outputId": "08dd5ade-7852-41d1-b6bd-5ddc75efab24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8189"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pic2label = {}\n",
        "for i in range(len(labels_vector['labels'][0])):\n",
        "  filename = f'image_{str(i+1).zfill(5)}.jpg'\n",
        "  pic2label[filename] = labels_vector['labels'][0][i]\n",
        "len(pic2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCD8HJQtCCiF"
      },
      "source": [
        "Splitting data to dirs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VI6mgT9CHdJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_dir = os.path.join(pictures_dir,'dataset')\n",
        "if split:\n",
        "  print(\"SPLITING!!\")\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "  # Create directories for each class\n",
        "  for label in set(pic2label.values()):\n",
        "    class_dir = os.path.join(dataset_dir, f'class_{label}')\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "  # Move files into the appropriate class folders\n",
        "  for filename, label in pic2label.items():\n",
        "    src_path = os.path.join(pictures_dir, filename)\n",
        "    dst_path = os.path.join(dataset_dir, f'class_{label}', filename)\n",
        "    shutil.move(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8S04j6hTKQj"
      },
      "source": [
        "Cross valdiation splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY-ItV-STNlK"
      },
      "outputs": [],
      "source": [
        "original_dataset = ImageFolder(root=dataset_dir, transform=None)\n",
        "labels = original_dataset.targets\n",
        "class_names = original_dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPhze7UeTdP_"
      },
      "outputs": [],
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # Train and Val+Test\n",
        "train_idx, val_test_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # Val and Test\n",
        "val_idx, test_idx = next(sss.split(np.zeros(len(val_test_idx)), np.array(labels)[val_test_idx]))\n",
        "\n",
        "train_dataset = Subset(original_dataset, train_idx)\n",
        "val_dataset = Subset(original_dataset, [val_test_idx[i] for i in val_idx])\n",
        "test_dataset = Subset(original_dataset, [val_test_idx[i] for i in test_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxfh2KPtWwas",
        "outputId": "c9a13128-8350-4228-83a8-4520718a30bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4094, 2047, 2048)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6uT2DXOZg1_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "def custom_collate(batch, trasnform):\n",
        "    images, labels = [], []\n",
        "    for img, label in batch:\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = trasnform(img)\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return torch.stack(images), torch.tensor(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpGKdCGM-uEK"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGTxmHpKN8Xw",
        "outputId": "0e650806-c4d0-49f6-cb9d-8875f92f57a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = len(classes)\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WTWoEyX-3bz"
      },
      "source": [
        "## Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMotCovP-6px"
      },
      "outputs": [],
      "source": [
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    print(f'Random seed set as {seed}')\n",
        "\n",
        "def get_device():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'Computation device: {device}')\n",
        "    return device\n",
        "\n",
        "def calculate_loss_and_accuracy(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, eval_loader, test_loader, num_epochs=25, patience = 7):\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    train_losses, eval_losses, test_losses = [], [], []\n",
        "    train_accuracies, eval_accuracies, test_accuracies = [], [], []\n",
        "    patience_counter = 0\n",
        "    best_eval_loss = float('inf')\n",
        "    patience = patience\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        eval_loss, eval_accuracy = calculate_loss_and_accuracy(model, eval_loader, criterion, device)\n",
        "        eval_losses.append(eval_loss)\n",
        "        eval_accuracies.append(eval_accuracy)\n",
        "\n",
        "        print(f\"Eval Loss: {eval_loss:.4f}, Eval Accuracy: {eval_accuracy:.4f}\")\n",
        "\n",
        "        if eval_loss < best_eval_loss:\n",
        "            best_eval_loss = eval_loss\n",
        "            patience_counter = 0\n",
        "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Early stopping patience counter: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    test_loss, test_accuracy = calculate_loss_and_accuracy(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(f\"Final Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return train_losses, eval_losses, test_losses, train_accuracies, eval_accuracies, test_accuracies\n",
        "\n",
        "def save_results(res, model_name, lr, batch_size):\n",
        "    base_dir = os.path.join('./results', model_name)\n",
        "    batch_size_dir = os.path.join(base_dir, f'{batch_size}_batch_size')\n",
        "    save_dir = os.path.join(batch_size_dir, f'{lr}_lr')\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_losses, eval_losses, test_losses, train_accuracies, eval_accuracies, test_accuracies = res\n",
        "    plot_lists(train_losses, eval_losses,  'Loss', save_dir)\n",
        "    plot_lists(train_accuracies, eval_accuracies, 'Accuracy', save_dir)\n",
        "\n",
        "    res_dict = {\n",
        "                'train_losses':train_losses,\n",
        "                'eval_losses':eval_losses,\n",
        "                'test_losses':test_losses,\n",
        "                'train_accuracies':train_accuracies,\n",
        "                'eval_accuracies':eval_accuracies,\n",
        "                'test_accuracies':test_accuracies\n",
        "               }\n",
        "    test_results = {\n",
        "                    'test_losses':test_losses,\n",
        "                    'test_accuracies':test_accuracies\n",
        "                   }\n",
        "\n",
        "    with open(os.path.join(save_dir, 'res_dict.json'), 'w') as f:\n",
        "        json.dump(res_dict, f)\n",
        "\n",
        "    with open(os.path.join(save_dir, 'test_res_dict.json'), 'w') as f:\n",
        "        json.dump(test_results, f)\n",
        "\n",
        "def plot_lists(train_values, eval_values, measurement, save_dir):\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(1, len(train_values) + 1), train_values, label='Train')\n",
        "    plt.plot(range(1, len(eval_values) + 1), eval_values, label='Eval')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(measurement)\n",
        "    plt.legend()\n",
        "    plt.title(f\"{model_name} - {measurement}\")\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"{measurement}.pdf\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Figure saved at: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhJVxmgvcZDc"
      },
      "outputs": [],
      "source": [
        "def get_vgg19_dataloaders(train_dataset, val_dataset, test_dataset, batch_size = 16):\n",
        "    vgg19_train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    vgg19_eval_test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    vgg19_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: custom_collate(x, vgg19_train_transform))\n",
        "    vgg19_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, vgg19_eval_test_transform))\n",
        "    vgg19_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, vgg19_eval_test_transform))\n",
        "    return vgg19_train_loader, vgg19_val_loader, vgg19_test_loader\n",
        "\n",
        "\n",
        "\n",
        "def run_vgg19_experiment(train_dataset, val_dataset, test_dataset, lr, batch_size):\n",
        "    vgg19 = models.vgg19(pretrained=True)\n",
        "    for param in vgg19.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    vgg19.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)\n",
        "    vgg19_train_loader, vgg19_val_loader, vgg19_test_loader = get_vgg19_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=batch_size)\n",
        "\n",
        "    res = train_model(vgg19, nn.CrossEntropyLoss(), torch.optim.Adam(vgg19.parameters(), lr=lr), vgg19_train_loader, vgg19_val_loader, vgg19_test_loader, num_epochs=100)\n",
        "    return res\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVeDzmpNcZDc"
      },
      "outputs": [],
      "source": [
        "def get_yolo_dataloaders(train_dataset, val_dataset, test_dataset, batch_size = 16):\n",
        "    yolo_train_transform = transforms.Compose([\n",
        "        transforms.Resize((640, 640)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    yolo_eval_test_transform = transforms.Compose([\n",
        "        transforms.Resize((640, 640)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    yolo_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: custom_collate(x, yolo_train_transform))\n",
        "    yolo_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, yolo_eval_test_transform))\n",
        "    yolo_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, yolo_eval_test_transform))\n",
        "    return yolo_train_loader, yolo_val_loader, yolo_test_loader\n",
        "\n",
        "def run_yolo_experiment(train_dataset, val_dataset, test_dataset, lr, batch_size):\n",
        "    yolo5 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "    yolo_backbone = yolo5.model.model.model[:10]\n",
        "    for param in yolo_backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    dummy_input = torch.randn(1, 3, 640, 640).to('cuda')\n",
        "    features = yolo_backbone(dummy_input)\n",
        "    print(features.shape)\n",
        "\n",
        "    feature_dim = features.shape[1] * features.shape[2] * features.shape[3]\n",
        "\n",
        "    yolo_classifier = nn.Sequential(\n",
        "        yolo_backbone,\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=feature_dim, out_features=1024),\n",
        "        nn.Linear(in_features=1024, out_features=num_classes)\n",
        "    ).to('cuda')\n",
        "\n",
        "    yolo_train_loader, yolo_val_loader, yolo_test_loader = get_yolo_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=batch_size)\n",
        "\n",
        "    res = train_model(yolo_classifier, nn.CrossEntropyLoss(), torch.optim.Adam(yolo_classifier.parameters(), lr=lr), yolo_train_loader, yolo_val_loader, yolo_test_loader, num_epochs=100)\n",
        "    return res\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1vGK3eHcZDc"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.models import resnet101, ResNet101_Weights\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "def get_resnet_dataloaders(train_dataset, val_dataset, test_dataset, batch_size):\n",
        "    resnet_train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    resnet_eval_test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "    resnet_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: custom_collate(x, resnet_train_transform))\n",
        "    resnet_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, resnet_eval_test_transform))\n",
        "    resnet_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: custom_collate(x, resnet_eval_test_transform))\n",
        "    return resnet_train_loader, resnet_val_loader, resnet_test_loader\n",
        "\n",
        "\n",
        "def run_resnet_experiment(train_dataset, val_dataset, test_dataset, model_name, lr, batch_size):\n",
        "    if model_name == 'resnet18':\n",
        "        resnet_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    elif model_name == 'resnet50':\n",
        "        resnet_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "    elif model_name == 'resnet101':\n",
        "        resnet_model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
        "    else:\n",
        "        raise Exception(\"Un supported ResnetModel\")\n",
        "\n",
        "    resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
        "\n",
        "\n",
        "    for param in resnet_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    for param in resnet_model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    resnet_train_loader, resnet_val_loader, resnet_test_loader = get_resnet_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=batch_size)\n",
        "    res = train_model(resnet_model, nn.CrossEntropyLoss(), torch.optim.Adam(resnet_model.parameters(), lr=lr), resnet_train_loader, resnet_val_loader, resnet_test_loader, num_epochs=100)\n",
        "    return res\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9PSHMzYcZDc"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32]\n",
        "models_to_test = ['vgg19', 'yolov5', 'resnet18']\n",
        "\n",
        "for model_name, lr, batch_size in itertools.product(models_to_test, lrs, batch_sizes):\n",
        "    if model_name == 'vgg19':\n",
        "        res = run_vgg19_experiment(train_dataset=train_dataset, val_dataset=val_dataset, test_dataset=test_dataset, lr=lr, batch_size=batch_size)\n",
        "    elif model_name == 'yolov5':\n",
        "        res = run_yolo_experiment(train_dataset=train_dataset, val_dataset=val_dataset, test_dataset=test_dataset, lr=lr, batch_size=batch_size)\n",
        "    elif 'resnet' in model_name:\n",
        "        res = run_resnet_experiment(train_dataset=train_dataset, val_dataset=val_dataset, test_dataset=test_dataset, model_name=model_name, lr=lr, batch_size=batch_size)\n",
        "    save_results(res=res, model_name=model_name, lr=lr, batch_size=batch_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Ass4ML)",
      "language": "python",
      "name": "ass4ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}